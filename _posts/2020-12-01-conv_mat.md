# Convolution, Circulant Matrices, and Graphs! 

## __INCOMPLETE__


## Convolution

Perhaps the most ubiquitous operation in digital signal processing is the application of filters on signals via convolution. The convolution operation is defined as:

$$ y[n] =(h * x)[n] = \sum_{m=0}^{N-1} h[n-m] x[m] $$

where $x[n]$ is the input signal with entries $(x_0, ..., x_{P-1})$, $h[n]$ is the filter with entries $(h_0, ..., h_{L-1})$, $y[n]$ is the output with entries $(y_0, ..., y_{N=P+L-1})$.

### Properties:

1. Linearity: 

$$c_1x_1[n] * h[n] + c_2x_2[n] * h[n] = (c_1x_1[n] + c_2x_2[n]) * h[n]$$

2. Commutivity:

$$x[n] * h[n] = h[n] * x[n]$$


## Delta function 

An interesting function is the delta function which is defined as: 

$$
\delta[n] =
    \begin{cases}
            1, &         \text{if } n = 0,\\
            0, &         \text{if } n \neq 0
    \end{cases}
$$

The delta function has an identity property under convolution:

$$ x[n] = x[n] * \delta[n] $$

Similarly a shifted delta function yields a shifted copy of the input sequence:

$$ x[n - m] = x[n] * \delta[n - m] $$

Any finite sequence $x[n]$ of length $P$ can be represented as a weighted sum (linear combination) of shifted delta functions

$$x[n] = \sum_{m=0}^{P-1} x_m \delta[n - m]$$

In fact, shifted delta functions serve as the basis vectors in time domain, and this is equivalent to a $P \times P$ identity matrix. Recall a vector can be expressed as a [linear combination](https://en.wikipedia.org/wiki/Linear_combination) of the columns of a matrix $A$ where the columns of $A$ are the basis vectors for that space:
$$ v = \sum_n c_n A_{:, n} $$

## Circular Convolution

A related operation is circular convolution: 

$$ y[n] = x[n] \circledast_N h[n] = \sum_{m=0}^{N-1} h[(n-m)\text{ mod } N] x[m] $$

Circular Convolution can be used to compute regular convolution (sometimes called linear convolution) if $x$ and $h$ are padded with zeros such that the new lengths equal $P + L - 1$, and the output truncated to the length of $P+L-1$. 

Example: 

* $\delta[n - 1] \circledast_P x[n]$ yields a circularly shifted sequence by one entry: $(x_{P-1}, x_0, ..., x_{P-2})$ 

## Fourier Transform


The Discrete Fourier Transform (DFT) of a signal $x[n]$ of length $N$ is defined as <a href="#ref_2">[1]</a> :

__Analysis:__

$$X[k] = \frac{1}{\sqrt{N}} \sum_{n = 0}^{N-1} x[n] W_N^{kn}$$

__Synthesis:__

$$x[n] = \frac{1}{\sqrt{N}} \sum_{n = 0}^{N-1} X[k] {W_N^*}^{kn}$$


where $W_N = e^{-j\frac{2\pi}{N}}$, $W_N^* = e^{j\frac{2\pi}{N}}$, and $0 \le k \le N-1$

The analysis portion of the DFT can be seen as a matrix muplication:


$$ X[0] = \frac{1}{\sqrt{N}}(x[0] + x[1] + x[2]... + x[N-1]) $$

$$ X[1] = \frac{1}{\sqrt{N}}(x[0] + x[1]W_N + x[2]W_N^2... + x[N-1]W_N^{N-1}) $$

$$ \vdots $$

$$ X[N-1] = \frac{1}{\sqrt{N}}(x[0] + x[1]W_N^{N-1} +x[2]W_N^{2(N-1)} + ... x[N-1]W_N^{(N-1)(N-1)}) $$

which is equivalent to 

$$ \begin{bmatrix} X[0] \\ X[1] \\ \vdots \\ X[N-1] \end{bmatrix} = 
\frac{1}{\sqrt{N}} 

\begin{bmatrix} 
1 & 1 & 1 & ... & 1 \\
1 & W_N & W_N^2 & ... & W_N^{N-1} \\
\vdots & \vdots & \vdots & ... & \vdots \\
1 & W_N^{N-1} & W_N^{2(N-1)} & ... & W_N^{(N-1)(N-1)} 
\end{bmatrix}

\begin{bmatrix}
x[0] \\
x[1] \\
x[2] \\
\vdots \\
x[N-1] 
\end{bmatrix}
$$

$$ X = Fx$$ 

where $F$ is the [Discrete Fourier Transform Matrix](https://en.wikipedia.org/wiki/DFT_matrix).
The synthesis formula can be similarly written as a matrix multiplication:

$$

\begin{bmatrix}
x[0] \\
x[1] \\
\vdots \\
x[N-1] 
\end{bmatrix}
= 
\frac{1}{\sqrt{N}} 
\begin{bmatrix} 
1 & 1 & 1 & ... & 1 \\
1 & W_N^* & {W_N^*}^2 & ... & {W_N^*}^{N-1} \\
\vdots & \vdots & \vdots & ... & \vdots \\
1 & {W_N^*}^{N-1} & {W_N^*}^{2(N-1)} & ... & {W_N^*}^{(N-1)(N-1)} 
\end{bmatrix}

\begin{bmatrix} X[0] \\ X[1] \\ \vdots \\ X[N-1] \end{bmatrix} 

$$

$$ x = F^*X $$


From the synthesis formulation above, one can see that the Fourier coefficients can be interpeted as coordinates with the columns as the basis vectors. The basis vectors consist of various sinusoidal forms.  The basis set consists of a set of $N$ functions enumerated by $k$ of the form $\omega_k[n]= e^{j\frac{2\pi}{N}kn}$ for $n=0,...,N-1$. Below are pictured the Fourier basis vectors for $N = 16$

<figure>
<img src="{{site.baseurl}}/images/post_im/circulant/basis.png">
  <figcaption>Fourier Basis for $N=16$ (The real part in blue, imaginary part in orange)</figcaption>
</figure>



### DFT and Circular Convolution

DFT can be used apply circular convolution:

$$
Y[k] = \frac{1}{\sqrt{N}} \sum_{n = 0}^{N-1} y[n] W_N^{kn}=
 \frac{1}{\sqrt{N}} \sum_{n = 0}^{N-1} W_N^{kn} \sum_{m=0}^{N-1} h[n-m \text{ mod } N] x[m] 
$$

$$
\frac{1}{\sqrt{N}} \sum_{n = 0}^{N-1} y[n] W_N^{kn}=
 \frac{1}{\sqrt{N}} \sum_{m=0}^{N-1} \sum_{n = 0}^{N-1} W_N^{kn}h[n-m \text{ mod } N] x[m] 
$$

Since the DFT of $h[n-m]$ equals $W_N^{km}H[k]$

$$
=\sum_{m=0}^{N-1} H[k] x[m] W_N^{km}
$$

$$
Y[k] = \sqrt{N}H[k]X[k] 
$$

Convolution reduces to element-wise multiplication in the Fourier domain.

## Circulant Matrices  

The entries in circulant matrices follow this pattern:

$$ H_{n,m} = h_{(n-m) \text { mod } N} $$

where $h \in \mathbb{R}^L$.

$$
H = \begin{bmatrix}
 h_0    & h_{1} & \cdots  & h_{L-1}   \\
 h_{L-1}    & h_0     & \cdots  & h_{L-2}   \\
 \vdots &         & \ddots & \vdots\\
 h_{1}& h_{2} & \cdots  & h_0   
\end{bmatrix}
$$


## Circulant Matrices and Convolution

If $H$ is circulant and $x \in \mathbb{R}^L$ then the entries of $y=Hx$ are given by:

$$y_n = \sum_m H_{n,m} x_m$$

$$y_n = \sum_m h_{(n-m) \text { mod } N}x_m$$

Thus, circular convolution can be expressed as matrix multiplication with a circulant matrix.


# Graphs and Signal Processing

The circular graph below can be interpreted as a regular signal progressing through the regular time steps and repeating after finishing.

<figure>
<img src="{{site.baseurl}}/images/post_im/circulant/cycle.png">
  <figcaption>Cycle Graph</figcaption>
</figure>

Also note that the graph's [adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix) $A$ is a circulant matrix as well:

$$
A = 
\begin{bmatrix}
  0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

The corresponding the eigenvectors of the adjacency matrix are shown below:

<figure>
<img src="{{site.baseurl}}/images/post_im/circulant/eigenbasis.png">
  <figcaption>Eignevectors of the Adjacency Matrix A</figcaption>
</figure>


# References:

<a id="ref_1"></a>
1. Oppenheim, Alan V., John R. Buck, and Ronald W. Schafer. Discrete-time signal processing. Vol. 2. Upper Saddle River, NJ: Prentice Hall, 2001.
<a id="ref_2"></a>
2. [Deriving convolution from first principles](https://towardsdatascience.com/deriving-convolution-from-first-principles-4ff124888028)
3. [Ortega, Antonio, et al. "Graph signal processing: Overview, challenges, and applications." Proceedings of the IEEE 106.5 (2018): 808-828.](https://arxiv.org/pdf/1712.00468.pdf)
4. [NYU Lecture Notes](https://www.math.nyu.edu/faculty/goodman/teaching/NumericalMethodsII2016/notes/lecture2.pdf)
5. [Bronstein, Michael M., et al. "Geometric deep learning: going beyond euclidean data." IEEE Signal Processing Magazine 34.4 (2017): 18-42.](https://arxiv.org/pdf/1611.08097.pdf)
4. [Gray, Robert M. Toeplitz and circulant matrices: A review. Now Publishers inc, 2006.](https://ee.stanford.edu/~gray/toeplitz.pdf)