# Generative Adversarial Networks (GANs)

The following contains my notes on the GANs paper by Goodfellow et al. 

# Prelimiaries and Definitions

## Definitions and Useful Theorems

* __Generative Model__:  Given a training set sampled from a distribution $p\_{\text{data}}(x)$, a generative model attempts to estimate $p\_{\text{data}}(x)$. The distribution of the model is denoted by $p\_{\text{model}}$ 
* __Zero Sum Game__:
* __Convex set__: A set $\mathcal{S}$ is a convex set if for any two members $x_1, x_2 \in \mathcal{S}$ and scalar $\alpha \in [0,1]$, the convex combination defined by $\alpha x_1 + (1-\alpha) x_2 \in S$.  
* __Convex function__: If $f$ is a convex function, then for all $\alpha \in [0,1]$ and $x_1, x_2 \in \mathcal{S}$, where $\mathcal{S}$ is a convex set, the following is true $f(\alpha x_1 + (1-\alpha) x_2) \leq \alpha f(x_1) + (1-\alpha) f(x_2)$.
* __Iterated Expectation__: For two random variables $X,Y$ , the following holds $\mathbb{E}\[g(X,Y)\] = \mathbb{E}\_{Y}\[ \mathbb{E}\_\{X\|Y\} \[g(X,Y)\] \]$ 
* __Kullback–Leibler (KL) divergence__: Measures the difference between two distributions $p(x)$ and $q(x)$. It is computed as follows: $$ \text{KL}(p||q) = - \int p(x) \log\bigg(\frac{q(x)}{p(x)}\bigg) dx = - \mathbb{E}_{p(x)} \log\bigg(\frac{q(x)}{p(x)}\bigg) $$.
The KL divergence is not symmetric $\text\{KL}\(p\|\|q) \neq \text\{KL\}(q\|\|p)$ and the measure is non-negative $\text{KL}(p\|\|q) \geq 0$ and it achieves equality if and only if $p(x) = q(x)$ 




## Maximum Likelihood Estimation (MLE)

Many generative models are trained using MLE. Given a model distribution $p\_\{\text{model}\}\(x;\theta\)$ with parameters $\theta$ and a dataset $\\{x_i\\}\_{i=1}^N$ sampled from $p\_{\text{data}}(x)$. The likelihood of the data under the given model is given by $\prod\_\{i=1\}^N p\_\{\text{model}\}(x\_i;\theta)$. ML estimation involves finding the parameters that maximize the likelihood of the data under the given model:

$$ \theta^* = \text{argmax}_\theta \prod_{i=1}^N p_{\text{model}}(x_i;\theta) $$

Since $0<a < b \implies \log a < \log b$,

$$ \theta^* = \text{argmax}_\theta \sum_{i=1}^N \log p_{\text{model}}(x_i;\theta)$$

Maximizing the ML is equivalent to minimizing the KL divergence between the $p\_{\text{data}}(x)$ and $p\_\{\text{model}\}\(x;\theta\)$:

$$ \text{argmax}_\theta \sum_{i=1}^N \log p_{\text{model}}(x_i;\theta)$$

$$ \text{argmin}_\theta -\frac{1}{N} \sum_{i=1}^N \log p_{\text{model}}(x_i;\theta)$$

$$ \text{argmin}_\theta -\frac{1}{N} \sum_{i=1}^N [\log p_{\text{model}}(x_i;\theta)  - \log p_{\text{data}}(x)]$$

Using the law of large numbers:

$$ \text{argmin}_\theta -\mathbb{E}_{p_{\text{data}}}[\log p_{\text{model}}(x_i;\theta)  - \log p_{\text{data}}(x)]$$

$$ \text{argmin}_\theta -\mathbb{E}_{p_{\text{data}}}[\frac{\log p_{\text{model}}(x_i;\theta)}{\log p_{\text{data}}(x)}]$$

# GANs

## Setup

# References:
1. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, BingXu, David Warde-Farley, Sherjil Ozair, Aaron Courville,and Yoshua Bengio,Generative adversarial nets, Advancesin neural information processing systems, 2014,pp. 2672–2680